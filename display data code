# Display the first few rows of the DataFrame
print("First 5 rows of the DataFrame:")
print(data.head())

# Optionally, display a random sample of rows
print("\nRandom sample of 5 rows from the DataFrame:")
print(data.sample(5))

# Display basic information about the DataFrame, including data types and non-null counts
print("\nBasic information about the DataFrame:")
print(data.info())

# Display summary statistics for numerical columns
print("\nSummary statistics for numerical columns:")
print(data.describe())

New line items:
# Drop rows where 'Product L2' is blank
data_filtered = data.dropna(subset=['Product L2'])

# Create pivot table
data_pivot = data_filtered.pivot_table(
    index=['Master Name', 'Master Industry', 'Product Region', 'Month', 'Year'],
    columns='Product L2',
    values='CV',
    aggfunc='sum'
)

# Display the pivot table
print(data_pivot)



solution to a problem:

if 'Product Level 2' in data_pivot.columns:
    print("Column 'Product Level 2' already exists")

data_pivot = data_pivot.drop(columns=['Product Level 2'])
# Or, you can rename it
data_pivot = data_pivot.rename(columns={'Product Level 2': 'Product Level 2_old'})





import pandas as pd
import numpy as np

# Load the data
csv_file_path = 'c:/Users/xhzys/Downloads/Global Market Extract Summary.csv'
data = pd.read_csv(csv_file_path)

# Ensure no duplicate column names
data.columns = data.columns.str.strip()

# Filter data by Product Region to include only 'Americas'
data_filtered = data[data['Product Region'] == 'Americas']

# Group by 'Month' and calculate the correlation matrix for each group
output_file = 'correlation_matrices.xlsx'
with pd.ExcelWriter(output_file) as writer:
    for month, group in data_filtered.groupby('Month'):
        # Calculate the correlation matrix
        correlation_matrix = group.corr()

        # Write the correlation matrix to a sheet named after the month
        correlation_matrix.to_excel(writer, sheet_name=str(month))

print(f"Correlation matrices have been saved to {output_file}.")

